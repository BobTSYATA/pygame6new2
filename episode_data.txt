Epoch: 458
Player 1 Actions: [(1, 1)]
Player 2 Actions: [(3, 1)]
Player 1 Rewards: [-10]
Player 2 Rewards: [-100]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.])]
==================================================
Epoch: 916
Player 1 Actions: [(1, 2), (1, 2)]
Player 2 Actions: [(2, 2)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,   0., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 1374
Player 1 Actions: [(1, 0), (0, 3), (0, 1), (0, 0), (1, 1), (1, 2), (1, 0), (1, 3), (1, 2), (1, 2), (1, 3), (1, 1), (1, 3)]
Player 2 Actions: [(2, 1), (1, 2), (2, 3), (3, 0), (3, 2), (2, 3), (2, 0), (2, 2), (0, 2), (2, 3), (3, 0), (0, 0), (0, 1)]
Player 1 Rewards: [10, -10, 10, -10, -10, -10, -10, -10, 10, -10, -10, -10, -10]
Player 2 Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   8., 200., 250.,   2.,  11., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   0., 600., 250.,   2.,  15.,
        400., 375.,   1.,   6.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,   2., 600., 250.,   2.,   0.,
        400., 375.,   2.,   9.]), tensor([400., 125.,   2.,  10., 200., 250.,   1.,   4., 600., 250.,   2.,   2.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,  12., 200., 250.,   1.,   1., 600., 250.,   2.,   6.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,  14., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   2.,   8.]), tensor([400., 125.,   2.,  16., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   2.,  18., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   2.,  18.,
        400., 375.,   2.,  12.]), tensor([400., 125.,   2.,   2., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   2.,  32.]), tensor([400., 125.,   2.,  36., 200., 250.,   1.,   1., 600., 250.,   2.,   2.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   2.,   4.,
        400., 375.,   2.,   2.])]
Next States: [tensor([400., 125.,   1.,   7., 200., 250.,   1.,   0., 600., 250.,   2.,  11.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,  12., 600., 250.,   2.,   1.,
        400., 375.,   1.,   5.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,   1., 600., 250.,   2.,  16.,
        400., 375.,   1.,   7.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,   3., 600., 250.,   2.,   1.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   2.,  11., 200., 250.,   1.,   0., 600., 250.,   2.,   3.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   2.,  13., 200., 250.,   1.,   0., 600., 250.,   2.,   5.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   2.,  13., 200., 250.,   1.,   0., 600., 250.,   2.,   1.,
        400., 375.,   2.,   9.]), tensor([400., 125.,   2.,  17., 200., 250.,   1.,   0., 600., 250.,   2.,   1.,
        400., 375.,   2.,   9.]), tensor([400., 125.,   2.,  19., 200., 250.,   1.,   0., 600., 250.,   1.,   1.,
        400., 375.,   2.,  11.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   0., 600., 250.,   2.,  17.,
        400., 375.,   2.,  13.]), tensor([400., 125.,   2.,   3., 200., 250.,   1.,   0., 600., 250.,   2.,   1.,
        400., 375.,   2.,  31.]), tensor([400., 125.,   2.,  37., 200., 250.,   1.,   0., 600., 250.,   2.,   3.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   0., 600., 250.,   2.,   5.,
        400., 375.,   2.,   1.])]
==================================================
Epoch: 1832
Player 1 Actions: [(0, 0), (0, 3), (0, 2)]
Player 2 Actions: [(2, 2), (2, 2)]
Player 1 Rewards: [-10, -8, 125]
Player 2 Rewards: [0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   2.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,  11.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   1.,
        400., 375.,   0.,   2.])]
==================================================
Epoch: 2290
Player 1 Actions: [(2, 2)]
Player 2 Actions: [(3, 2)]
Player 1 Rewards: [-10]
Player 2 Rewards: [-100]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   1.,  10.,
        400., 375.,   2.,  10.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   1.,   0.,
        400., 375.,   2.,  11.])]
==================================================
Epoch: 2748
Player 1 Actions: [(0, 0), (0, 3)]
Player 2 Actions: [(3, 3)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.])]
==================================================
Epoch: 3206
Player 1 Actions: [(1, 3), (1, 3), (1, 1), (1, 3)]
Player 2 Actions: [(0, 3), (3, 2), (0, 3), (3, 1)]
Player 1 Rewards: [-8, -10, -10, -8]
Player 2 Rewards: [0, 0, 0, -100]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   1.,  10., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   2.,   4.]), tensor([400., 125.,   2.,   2., 200., 250.,   1.,   1., 600., 250.,   0.,   0.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   0.,   0.,
        400., 375.,   2.,   6.])]
Next States: [tensor([400., 125.,   2.,  11., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   1.,   7.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   2.,   3.]), tensor([400., 125.,   2.,   3., 200., 250.,   1.,   0., 600., 250.,   0.,   0.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   0., 600., 250.,   0.,   0.,
        400., 375.,   2.,   5.])]
==================================================
Epoch: 3664
Player 1 Actions: [(0, 0), (0, 1), (1, 2), (1, 2), (2, 0), (0, 0), (0, 0), (0, 3), (3, 0), (0, 0), (0, 0), (0, 0)]
Player 2 Actions: [(1, 3), (3, 0), (3, 3), (0, 1), (1, 2), (3, 3), (3, 1), (1, 1), (1, 3), (1, 2), (3, 3), (3, 0)]
Player 1 Rewards: [-10, 10, -8, -3, 10, -10, -10, 10, -10, -10, -10, -10]
Player 2 Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   2.,  10., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   2.,   8.]), tensor([400., 125.,   2.,   9., 200., 250.,   1.,   2., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,  11., 200., 250.,   1.,   1., 600., 250.,   0.,   1.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   2.,  12., 600., 250.,   1.,   2.,
        400., 375.,   2.,   2.]), tensor([400., 125.,   1.,   3., 200., 250.,   2.,   0., 600., 250.,   2.,  13.,
        400., 375.,   2.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   2., 600., 250.,   2.,  15.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   6., 600., 250.,   2.,  17.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   0., 600., 250.,   2.,  19.,
        400., 375.,   1.,   2.]), tensor([400., 125.,   1.,   6., 200., 250.,   2.,   0., 600., 250.,   2.,  21.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   0., 600., 250.,   2.,  25.,
        400., 375.,   2.,   3.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   2., 600., 250.,   2.,  27.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   2.,  11., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   2.,   9.]), tensor([400., 125.,   2.,  10., 200., 250.,   1.,   0., 600., 250.,   0.,   1.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   2.,  12., 200., 250.,   1.,   0., 600., 250.,   1.,   1.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   1.,   2., 200., 250.,   2.,  13., 600., 250.,   1.,   0.,
        400., 375.,   2.,   3.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,   1., 600., 250.,   2.,  14.,
        400., 375.,   2.,   5.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,   3., 600., 250.,   2.,  16.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,   7., 600., 250.,   2.,  18.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   1.,   5., 200., 250.,   2.,   1., 600., 250.,   2.,  20.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,   1., 600., 250.,   2.,  22.,
        400., 375.,   2.,   2.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,   1., 600., 250.,   2.,  26.,
        400., 375.,   2.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,   3., 600., 250.,   2.,  28.,
        400., 375.,   2.,   1.])]
==================================================
Epoch: 4122
Player 1 Actions: [(1, 2), (1, 3)]
Player 2 Actions: [(3, 3)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   1., 600., 250.,   1.,   8.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,   0., 600., 250.,   1.,   7.,
        400., 375.,   2.,  11.])]
==================================================
Epoch: 4580
Player 1 Actions: [(3, 1), (3, 0), (3, 2)]
Player 2 Actions: [(0, 2), (2, 1)]
Player 1 Rewards: [-3, 10, 110]
Player 2 Rewards: [0, 0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   8., 600., 250.,   2.,   8.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   1.,   2., 200., 250.,   1.,   0., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   2.,  11., 200., 250.,   1.,   7., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,   9., 600., 250.,   2.,   9.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 458
Player 1 Actions: [(1, 1), (1, 2), (1, 2), (1, 3), (1, 2), (1, 0), (0, 0)]
Player 2 Actions: [(2, 0), (0, 2), (0, 0), (0, 0), (0, 3), (2, 1), (2, 0)]
Player 1 Rewards: [-10, 10, -10, -10, -10, -8, -10]
Player 2 Rewards: [0, 0, 0, 0, 0, 0, -100]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   8., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   2.,   8.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   2.,   8.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   2.,  10.,
        400., 375.,   0.,   2.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   2.,  10.,
        400., 375.,   0.,   0.]), tensor([400., 125.,   1.,   2., 200., 250.,   2.,  11., 600., 250.,   2.,   0.,
        400., 375.,   0.,   0.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,   0., 600., 250.,   2.,  11.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   9., 200., 250.,   1.,   0., 600., 250.,   1.,   1.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   0., 600., 250.,   2.,   7.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   0., 600., 250.,   2.,   9.,
        400., 375.,   0.,   2.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   0., 600., 250.,   2.,   9.,
        400., 375.,   0.,   2.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,   0., 600., 250.,   2.,  11.,
        400., 375.,   0.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,  12., 600., 250.,   2.,   1.,
        400., 375.,   0.,   0.])]
==================================================
Epoch: 916
Player 1 Actions: [(1, 0), (1, 0)]
Player 2 Actions: [(0, 3)]
Player 1 Rewards: [-8, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   1.,  10., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   0.,   3.])]
Next States: [tensor([400., 125.,   2.,   0., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.])]
==================================================
