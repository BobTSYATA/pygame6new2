Epoch: 458
Player 1 Actions: [(1, 0), (1, 2), (1, 1)]
Player 2 Actions: [(0, 0), (0, 2), (0, 1)]
Player 1 Rewards: [-8, -10, -10]
Player 2 Rewards: [0, 0, -100]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   1.,  10., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   0.,   0.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   2.,   0., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   0., 600., 250.,   0.,   2.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   0., 600., 250.,   0.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 916
Player 1 Actions: [(3, 1), (1, 3)]
Player 2 Actions: [(2, 3), (3, 1)]
Player 1 Rewards: [-10, -8]
Player 2 Rewards: [0, -100]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   8., 600., 250.,   2.,   0.,
        400., 375.,   2.,  11.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,   7., 600., 250.,   2.,  11.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   0., 600., 250.,   2.,   1.,
        400., 375.,   2.,   3.])]
==================================================
Epoch: 1374
Player 1 Actions: [(0, 1), (1, 0), (1, 0)]
Player 2 Actions: [(3, 0), (3, 0), (3, 1)]
Player 1 Rewards: [10, -8, -8]
Player 2 Rewards: [0, 0, -100]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   2.,  11., 200., 250.,   1.,   8., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   6., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   1.,   7., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.]), tensor([400., 125.,   2.,   3., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   2.,   5., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   2.,   1.])]
==================================================
Epoch: 1832
Player 1 Actions: [(1, 1), (1, 1), (1, 0)]
Player 2 Actions: [(0, 0), (0, 0)]
Player 1 Rewards: [-10, -10, 110]
Player 2 Rewards: [0, 0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   1.,  10., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   2.,  11., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 2290
Player 1 Actions: [(3, 0), (3, 0), (0, 2), (2, 0), (0, 2), (0, 1), (2, 3)]
Player 2 Actions: [(2, 2), (2, 3), (3, 3), (3, 2), (3, 3), (3, 3)]
Player 1 Rewards: [10, -10, 25, -10, -8, -8, 125]
Player 2 Rewards: [0, 0, 0, 0, 0, 0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   1.,   8., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   1.,  12., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   1.,  13.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,  17., 200., 250.,   0.,   4., 600., 250.,   2.,   1.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   1.,  17.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   2., 600., 250.,   1.,  19.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   1.,   7., 200., 250.,   0.,   4., 600., 250.,   2.,  11.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,  11., 200., 250.,   0.,   4., 600., 250.,   2.,   1.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,  12.,
        400., 375.,   2.,   2.]), tensor([400., 125.,   1.,  16., 200., 250.,   0.,   4., 600., 250.,   1.,   0.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,  16.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   2., 600., 250.,   1.,  18.,
        400., 375.,   2.,   1.])]
==================================================
Epoch: 2748
Player 1 Actions: [(0, 3), (3, 0), (0, 3), (3, 0), (0, 3), (3, 0), (0, 1), (3, 1), (3, 0), (3, 0), (1, 1), (0, 3), (3, 0), (0, 3), (3, 0), (0, 3), (3, 0), (0, 2), (0, 1), (1, 1), (1, 3), (2, 3), (3, 2), (2, 0), (0, 3)]
Player 2 Actions: [(2, 2), (2, 2), (2, 2), (2, 3), (2, 0), (2, 2), (2, 0), (0, 0), (2, 2), (2, 0), (2, 0), (2, 1), (2, 2), (2, 1), (2, 1), (2, 2), (2, 3), (3, 2), (3, 0), (3, 3), (0, 0), (0, 0), (0, 3), (3, 1)]
Player 1 Rewards: [-10, -10, -10, -10, -8, -10, -8, -10, 10, -10, -10, -10, -10, -10, -10, -10, -10, 10, -10, -10, 10, -10, -10, 10, 110]
Player 2 Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,   8.]), tensor([400., 125.,   1.,  12., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,  16.]), tensor([400., 125.,   1.,  20., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   2.,   1., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,  20.]), tensor([400., 125.,   1.,  20., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,  18., 600., 250.,   2.,   0.,
        400., 375.,   1.,   3.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,  24., 600., 250.,   2.,   2.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   1.,   2., 200., 250.,   1.,  26., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   1.,   4., 200., 250.,   1.,  28., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   1.,   4., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   1.,   3.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   1.,  14., 200., 250.,   1.,   3., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,   3., 600., 250.,   2.,   0.,
        400., 375.,   1.,  18.]), tensor([400., 125.,   1.,  22., 200., 250.,   1.,   3., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,   5., 600., 250.,   2.,   0.,
        400., 375.,   1.,  26.]), tensor([400., 125.,   1.,  30., 200., 250.,   1.,   7., 600., 250.,   2.,   0.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,   9., 600., 250.,   1.,  28.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,  13., 600., 250.,   1.,  30.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   3., 200., 250.,   1.,   1., 600., 250.,   1.,  32.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   1.,  34.,
        400., 375.,   1.,   2.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   3., 600., 250.,   1.,   1.,
        400., 375.,   1.,  39.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   5., 600., 250.,   1.,  43.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   1.,  44., 200., 250.,   1.,   4., 600., 250.,   1.,   1.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,  11.,
        400., 375.,   1.,   7.]), tensor([400., 125.,   1.,  11., 200., 250.,   0.,   4., 600., 250.,   2.,   1.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   1.,
        400., 375.,   1.,  15.]), tensor([400., 125.,   1.,  19., 200., 250.,   0.,   4., 600., 250.,   2.,   1.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   1.,
        400., 375.,   1.,  19.]), tensor([400., 125.,   1.,  19., 200., 250.,   0.,   4., 600., 250.,   2.,   1.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,  17., 600., 250.,   2.,   1.,
        400., 375.,   1.,   2.]), tensor([400., 125.,   2.,   2., 200., 250.,   1.,  23., 600., 250.,   2.,   1.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,  25., 600., 250.,   2.,   3.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   5., 200., 250.,   1.,  27., 600., 250.,   2.,   1.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   5., 200., 250.,   1.,   0., 600., 250.,   2.,   1.,
        400., 375.,   1.,   2.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,   2., 600., 250.,   2.,   1.,
        400., 375.,   1.,   9.]), tensor([400., 125.,   1.,  13., 200., 250.,   1.,   2., 600., 250.,   2.,   1.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,   4., 600., 250.,   2.,   1.,
        400., 375.,   1.,  17.]), tensor([400., 125.,   1.,  21., 200., 250.,   1.,   4., 600., 250.,   2.,   1.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,   4., 600., 250.,   2.,   1.,
        400., 375.,   1.,  25.]), tensor([400., 125.,   1.,  29., 200., 250.,   1.,   6., 600., 250.,   2.,   1.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,   8., 600., 250.,   1.,  30.,
        400., 375.,   2.,   2.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,  12., 600., 250.,   1.,  29.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   2.,   2., 200., 250.,   1.,   0., 600., 250.,   1.,  31.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   2.,   4., 200., 250.,   1.,   0., 600., 250.,   1.,  33.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   2., 600., 250.,   1.,   0.,
        400., 375.,   1.,  38.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   4., 600., 250.,   1.,  42.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,  43., 200., 250.,   1.,   6., 600., 250.,   1.,   0.,
        400., 375.,   2.,   2.])]
==================================================
Epoch: 3206
Player 1 Actions: [(1, 1)]
Player 2 Actions: [(0, 1)]
Player 1 Rewards: [-10]
Player 2 Rewards: [-100]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   1.,  10., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   2.,  11., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 3664
Player 1 Actions: [(1, 0), (1, 3), (3, 3), (3, 0)]
Player 2 Actions: [(3, 0), (0, 0), (0, 1)]
Player 1 Rewards: [10, 25, -10, 110]
Player 2 Rewards: [0, 0, 0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   2.,   4., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   1.,   2.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   1.,   7., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.]), tensor([400., 125.,   2.,   5., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   2., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 4122
Player 1 Actions: [(1, 0), (1, 0)]
Player 2 Actions: [(0, 2)]
Player 1 Rewards: [-8, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   1.,  10., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   0.,   3.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   2.,   0., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 4580
Player 1 Actions: [(2, 0), (2, 0)]
Player 2 Actions: [(0, 0)]
Player 1 Rewards: [-8, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   0.,   4., 600., 250.,   1.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,   1.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 5038
Player 1 Actions: [(1, 0), (1, 0), (0, 1), (1, 2), (2, 0)]
Player 2 Actions: [(2, 2), (2, 0), (2, 0), (0, 3)]
Player 1 Rewards: [10, -10, -10, 10, 110]
Player 2 Rewards: [0, 0, 0, 0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   8., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,  10., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,  14., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   1.,  15.,
        400., 375.,   0.,   1.])]
Next States: [tensor([400., 125.,   1.,   7., 200., 250.,   1.,   0., 600., 250.,   2.,  11.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,  11., 200., 250.,   1.,   0., 600., 250.,   2.,   1.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,  13., 600., 250.,   2.,   1.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   2., 200., 250.,   1.,   0., 600., 250.,   1.,  14.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 5496
Player 1 Actions: [(1, 0), (0, 3), (0, 1)]
Player 2 Actions: [(3, 1), (1, 1)]
Player 1 Rewards: [10, 25, 110]
Player 2 Rewards: [0, 0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   1.,   8., 200., 250.,   2.,  11., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   1.,   9.])]
Next States: [tensor([400., 125.,   1.,   7., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,  12., 600., 250.,   0.,   4.,
        400., 375.,   1.,   8.])]
==================================================
Epoch: 5954
Player 1 Actions: [(2, 0), (0, 0)]
Player 2 Actions: [(1, 2), (2, 0)]
Player 1 Rewards: [10, -10]
Player 2 Rewards: [0, -100]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   2.,  10., 600., 250.,   1.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   8., 200., 250.,   2.,   0., 600., 250.,   2.,  11.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   1.,   7., 200., 250.,   2.,  11., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,   1., 600., 250.,   2.,  12.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 6412
Player 1 Actions: [(1, 0), (0, 3)]
Player 2 Actions: [(3, 3)]
Player 1 Rewards: [10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   1.,   8., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   1.,   7., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.])]
==================================================
Epoch: 6870
Player 1 Actions: [(0, 0), (0, 2)]
Player 2 Actions: [(2, 2)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,  11.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 7328
Player 1 Actions: [(0, 1), (1, 2), (1, 3), (1, 1), (1, 3), (3, 0)]
Player 2 Actions: [(2, 3), (3, 0), (0, 3), (3, 3), (0, 2)]
Player 1 Rewards: [10, 10, 10, -10, 10, 110]
Player 2 Rewards: [0, 0, 0, 0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,   8., 600., 250.,   2.,   0.,
        400., 375.,   2.,   8.]), tensor([400., 125.,   2.,   7., 200., 250.,   1.,   1., 600., 250.,   1.,   9.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   1.,  11.,
        400., 375.,   2.,   7.]), tensor([400., 125.,   2.,   2., 200., 250.,   1.,   1., 600., 250.,   1.,  13.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   1.,  11.,
        400., 375.,   1.,   2.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   1.,   7., 600., 250.,   2.,  11.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   2., 200., 250.,   1.,   0., 600., 250.,   1.,   8.,
        400., 375.,   2.,   9.]), tensor([400., 125.,   2.,   8., 200., 250.,   1.,   0., 600., 250.,   1.,  10.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   0., 600., 250.,   1.,  12.,
        400., 375.,   2.,   8.]), tensor([400., 125.,   2.,   3., 200., 250.,   1.,   0., 600., 250.,   1.,  14.,
        400., 375.,   1.,   1.])]
==================================================
Epoch: 7786
Player 1 Actions: [(1, 2), (1, 2)]
Player 2 Actions: [(2, 0)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   0.,   3., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,   0., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 8244
Player 1 Actions: [(0, 1), (0, 3)]
Player 2 Actions: [(3, 3)]
Player 1 Rewards: [10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,   8., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   1.,   7., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.])]
==================================================
Epoch: 8702
Player 1 Actions: [(0, 1), (0, 1)]
Player 2 Actions: [(1, 3)]
Player 1 Rewards: [-8, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   2.,  10., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   3.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 9160
Player 1 Actions: [(1, 2), (1, 2)]
Player 2 Actions: [(2, 2)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,   0., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 9618
Player 1 Actions: [(3, 0), (3, 0)]
Player 2 Actions: [(0, 2)]
Player 1 Rewards: [-8, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   3.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 10076
Player 1 Actions: [(3, 2), (3, 2)]
Player 2 Actions: [(2, 0)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   0.,   3., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 10534
Player 1 Actions: [(3, 0), (3, 1), (3, 0), (3, 2)]
Player 2 Actions: [(1, 0), (0, 2), (2, 2)]
Player 1 Rewards: [10, 10, 10, 110]
Player 2 Rewards: [0, 0, 0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   2.,  10., 600., 250.,   0.,   4.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   2.,   4., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   2., 600., 250.,   2.,   2.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   1.,   2., 200., 250.,   1.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   1.,   7., 200., 250.,   2.,  11., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   2.,   5., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,   3., 600., 250.,   2.,   3.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 10992
Player 1 Actions: [(3, 0), (0, 1), (3, 1), (1, 2), (2, 0), (0, 1), (1, 3), (3, 0)]
Player 2 Actions: [(1, 2), (2, 0), (0, 3), (0, 1), (1, 0), (3, 0), (0, 0)]
Player 1 Rewards: [10, 10, -10, -10, 10, 10, 10, 110]
Player 2 Rewards: [0, 0, 0, 0, 0, 0, 0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   2.,  10., 600., 250.,   0.,   4.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   1.,   8., 200., 250.,   2.,   0., 600., 250.,   2.,   8.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   2.,   9., 200., 250.,   1.,   9., 600., 250.,   2.,   0.,
        400., 375.,   1.,   3.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,  15., 600., 250.,   2.,   2.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   2.,   0., 200., 250.,   2.,   1., 600., 250.,   1.,  14.,
        400., 375.,   2.,  12.]), tensor([400., 125.,   1.,  12., 200., 250.,   2.,   0., 600., 250.,   1.,   1.,
        400., 375.,   2.,  14.]), tensor([400., 125.,   2.,  15., 200., 250.,   1.,  13., 600., 250.,   1.,   3.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   1.,   5.,
        400., 375.,   1.,  14.])]
Next States: [tensor([400., 125.,   1.,   7., 200., 250.,   2.,  11., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,   8., 600., 250.,   2.,   9.,
        400., 375.,   1.,   2.]), tensor([400., 125.,   2.,  10., 200., 250.,   1.,  14., 600., 250.,   2.,   1.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   0., 600., 250.,   1.,  13.,
        400., 375.,   2.,  11.]), tensor([400., 125.,   1.,  14., 200., 250.,   2.,   2., 600., 250.,   1.,   0.,
        400., 375.,   2.,  13.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,  12., 600., 250.,   1.,   2.,
        400., 375.,   2.,  15.]), tensor([400., 125.,   2.,  16., 200., 250.,   1.,   0., 600., 250.,   1.,   4.,
        400., 375.,   1.,  13.])]
==================================================
Epoch: 11450
Player 1 Actions: [(0, 1), (0, 1)]
Player 2 Actions: [(1, 3)]
Player 1 Rewards: [-8, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   2.,  10., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   3.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 11908
Player 1 Actions: [(3, 1), (3, 1)]
Player 2 Actions: [(1, 2)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   2.,  10., 600., 250.,   0.,   4.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   0.,   4., 200., 250.,   2.,   0., 600., 250.,   0.,   3.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 12366
Player 1 Actions: [(3, 1), (3, 2), (2, 1)]
Player 2 Actions: [(2, 1), (1, 1)]
Player 1 Rewards: [-10, 25, 125]
Player 2 Rewards: [0, 0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   0.,   4., 200., 250.,   2.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   0.,   4., 200., 250.,   2.,   0., 600., 250.,   1.,   2.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,   7., 600., 250.,   2.,  11.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   0.,   4., 200., 250.,   2.,   5., 600., 250.,   1.,   1.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 12824
Player 1 Actions: [(0, 3), (0, 1), (3, 2), (2, 1), (0, 3)]
Player 2 Actions: [(1, 2), (2, 1), (1, 3), (3, 1)]
Player 1 Rewards: [-8, 10, 10, 10, 110]
Player 2 Rewards: [0, 0, 0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   2.,  10., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   0., 600., 250.,   2.,   8.,
        400., 375.,   1.,   8.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   8., 600., 250.,   2.,   0.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   1.,   3., 200., 250.,   2.,   0., 600., 250.,   1.,  11.,
        400., 375.,   2.,   9.]), tensor([400., 125.,   1.,   5., 200., 250.,   1.,   1., 600., 250.,   1.,   1.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   2.,  11., 600., 250.,   0.,   4.,
        400., 375.,   1.,   7.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,   1., 600., 250.,   2.,   9.,
        400., 375.,   1.,   9.]), tensor([400., 125.,   1.,   2., 200., 250.,   2.,   9., 600., 250.,   1.,  10.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   4., 200., 250.,   1.,  11., 600., 250.,   1.,   0.,
        400., 375.,   2.,  10.])]
==================================================
Epoch: 13282
Player 1 Actions: [(2, 2), (2, 0)]
Player 2 Actions: [(0, 0)]
Player 1 Rewards: [-10, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   0.,   4., 600., 250.,   1.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,   1.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   2.,  11., 200., 250.,   0.,   4., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 13740
Player 1 Actions: [(2, 1), (2, 1), (2, 1)]
Player 2 Actions: [(1, 2), (1, 0)]
Player 1 Rewards: [-10, 15, 125]
Player 2 Rewards: [0, 0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   2.,  10., 600., 250.,   1.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   0.,   4., 200., 250.,   2.,   0., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   0.,   3., 200., 250.,   2.,   0., 600., 250.,   1.,   1.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   2.,   0., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   0.,   4., 200., 250.,   2.,   0., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 14198
Player 1 Actions: [(1, 1), (1, 3), (1, 2), (1, 3), (3, 2), (3, 1), (2, 0), (0, 3)]
Player 2 Actions: [(3, 2), (2, 3), (3, 2), (2, 1), (1, 0), (0, 3), (3, 3)]
Player 1 Rewards: [-10, 25, 25, 25, 25, 10, 10, 110]
Player 2 Rewards: [0, 0, 0, 0, 0, 0, 0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   1., 600., 250.,   2.,   8.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   2.,   8.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   1., 600., 250.,   2.,   8.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   0.,   4., 200., 250.,   2.,   9., 600., 250.,   2.,   0.,
        400., 375.,   1.,   2.]), tensor([400., 125.,   2.,   7., 200., 250.,   2.,   0., 600., 250.,   1.,   3.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   2., 600., 250.,   1.,   5.,
        400., 375.,   2.,   8.]), tensor([400., 125.,   1.,   6., 200., 250.,   1.,   4., 600., 250.,   1.,   1.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   0., 600., 250.,   2.,   9.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   0., 600., 250.,   1.,   1.,
        400., 375.,   2.,   9.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   0., 600., 250.,   2.,   9.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   0.,   4., 200., 250.,   2.,  10., 600., 250.,   1.,   2.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   2.,   8., 200., 250.,   1.,   1., 600., 250.,   1.,   4.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   5., 200., 250.,   1.,   3., 600., 250.,   1.,   0.,
        400., 375.,   2.,   9.])]
==================================================
Epoch: 14656
Player 1 Actions: [(0, 1), (1, 3), (1, 2), (0, 3), (3, 2), (0, 1)]
Player 2 Actions: [(3, 2), (2, 3), (3, 1), (1, 2), (1, 0)]
Player 1 Rewards: [10, 10, 10, 10, -10, 110]
Player 2 Rewards: [0, 0, 0, 0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,   8., 600., 250.,   2.,   8.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   3., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   1.,   5., 200., 250.,   2.,   2., 600., 250.,   1.,   2.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   0., 600., 250.,   1.,   0.,
        400., 375.,   1.,   6.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   0., 600., 250.,   1.,   9.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   1.,   7., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.]), tensor([400., 125.,   1.,   2., 200., 250.,   1.,   0., 600., 250.,   2.,   9.,
        400., 375.,   1.,   8.]), tensor([400., 125.,   1.,   4., 200., 250.,   1.,   0., 600., 250.,   1.,   1.,
        400., 375.,   2.,   2.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,   3., 600., 250.,   1.,   3.,
        400., 375.,   1.,   5.]), tensor([400., 125.,   1.,   2., 200., 250.,   2.,   1., 600., 250.,   1.,   8.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 15114
Player 1 Actions: [(3, 1), (1, 0), (0, 3)]
Player 2 Actions: [(0, 3), (3, 3)]
Player 1 Rewards: [-3, 10, 125]
Player 2 Rewards: [0, 0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   8., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.]), tensor([400., 125.,   1.,   9., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   2.,  11., 200., 250.,   1.,   7., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   8., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   2.,  12.])]
==================================================
Epoch: 15572
Player 1 Actions: [(3, 2), (3, 2)]
Player 2 Actions: [(2, 0)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   0.,   3., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 16030
Player 1 Actions: [(2, 0), (2, 0)]
Player 2 Actions: [(0, 1)]
Player 1 Rewards: [-8, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   0.,   4., 600., 250.,   1.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   0.,   3., 600., 250.,   1.,   1.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 16488
Player 1 Actions: [(1, 2), (1, 3)]
Player 2 Actions: [(3, 3)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   1., 600., 250.,   1.,   8.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,   0., 600., 250.,   1.,   7.,
        400., 375.,   2.,  11.])]
==================================================
Epoch: 16946
Player 1 Actions: [(2, 0), (2, 0)]
Player 2 Actions: [(0, 0)]
Player 1 Rewards: [-8, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   0.,   4., 600., 250.,   1.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,   1.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 17404
Player 1 Actions: [(1, 0), (1, 2)]
Player 2 Actions: [(2, 2)]
Player 1 Rewards: [10, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,  10., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   8., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   1.,   7., 200., 250.,   1.,   0., 600., 250.,   2.,  11.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 17862
Player 1 Actions: [(3, 0), (3, 1)]
Player 2 Actions: [(1, 1)]
Player 1 Rewards: [10, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   2.,  10., 600., 250.,   0.,   4.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   1.,   8., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   1.,   7., 200., 250.,   2.,  11., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 18320
Player 1 Actions: [(2, 1), (2, 0), (1, 3), (3, 0)]
Player 2 Actions: [(0, 3), (3, 0), (0, 0)]
Player 1 Rewards: [-3, 10, 10, 110]
Player 2 Rewards: [0, 0, 0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   0.,   4., 600., 250.,   1.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   8., 600., 250.,   1.,   1.,
        400., 375.,   2.,   8.]), tensor([400., 125.,   2.,   8., 200., 250.,   1.,  10., 600., 250.,   1.,   1.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   1.,   3.,
        400., 375.,   1.,  11.])]
Next States: [tensor([400., 125.,   2.,  11., 200., 250.,   1.,   7., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,   9., 600., 250.,   1.,   0.,
        400., 375.,   2.,   9.]), tensor([400., 125.,   2.,   9., 200., 250.,   1.,   0., 600., 250.,   1.,   2.,
        400., 375.,   1.,  10.])]
==================================================
Epoch: 18778
Player 1 Actions: [(0, 2), (2, 3), (3, 0)]
Player 2 Actions: [(3, 0), (0, 0)]
Player 1 Rewards: [-10, 25, 110]
Player 2 Rewards: [0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   2.,  11., 200., 250.,   0.,   4., 600., 250.,   1.,   8.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,   1.,
        400., 375.,   1.,   9.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,   7.,
        400., 375.,   2.,  11.]), tensor([400., 125.,   2.,  12., 200., 250.,   0.,   4., 600., 250.,   1.,   0.,
        400., 375.,   1.,   8.])]
==================================================
Epoch: 19236
Player 1 Actions: [(0, 1), (1, 2), (2, 2), (2, 2), (1, 3), (2, 2), (1, 3), (1, 2), (1, 2)]
Player 2 Actions: [(3, 0), (0, 0), (0, 3), (3, 0), (0, 3), (3, 2), (2, 3), (0, 2), (3, 1)]
Player 1 Rewards: [10, -8, -10, -10, 10, -10, 10, 10, -10]
Player 2 Rewards: [0, 0, 0, 0, 0, 0, 0, 0, -100]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   2.,  11., 200., 250.,   1.,   8., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   1.,   6.,
        400., 375.,   2.,   2.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   3., 600., 250.,   1.,   1.,
        400., 375.,   2.,   6.]), tensor([400., 125.,   2.,  10., 200., 250.,   1.,   5., 600., 250.,   1.,   1.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   1.,   3.,
        400., 375.,   2.,   6.]), tensor([400., 125.,   2.,   2., 200., 250.,   1.,   3., 600., 250.,   2.,   7.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   4., 200., 250.,   1.,   1., 600., 250.,   2.,   0.,
        400., 375.,   2.,   5.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   1., 600., 250.,   2.,   4.,
        400., 375.,   2.,   7.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   1.,   7., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.]), tensor([400., 125.,   2.,  12., 200., 250.,   1.,   0., 600., 250.,   1.,   5.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   2., 600., 250.,   1.,   0.,
        400., 375.,   2.,   3.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   4., 600., 250.,   1.,   0.,
        400., 375.,   2.,   7.]), tensor([400., 125.,   2.,  11., 200., 250.,   1.,   0., 600., 250.,   1.,   2.,
        400., 375.,   1.,   5.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   2., 600., 250.,   1.,   0.,
        400., 375.,   2.,   7.]), tensor([400., 125.,   2.,   3., 200., 250.,   1.,   0., 600., 250.,   2.,   8.,
        400., 375.,   1.,   3.]), tensor([400., 125.,   2.,   5., 200., 250.,   1.,   0., 600., 250.,   1.,   1.,
        400., 375.,   2.,   6.]), tensor([400., 125.,   2.,   1., 200., 250.,   1.,   0., 600., 250.,   2.,   3.,
        400., 375.,   2.,   8.])]
==================================================
Epoch: 19694
Player 1 Actions: [(0, 1), (1, 3), (3, 0), (0, 3), (0, 1), (1, 3), (3, 1), (3, 1), (3, 0)]
Player 2 Actions: [(3, 0), (0, 1), (1, 3), (1, 1), (3, 0), (0, 1), (1, 1), (0, 0)]
Player 1 Rewards: [10, 25, 10, -10, 10, 25, -10, 10, 110]
Player 2 Rewards: [0, 0, 0, 0, 0, 0, 0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   2.,  11., 200., 250.,   1.,   8., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   2.,  12., 600., 250.,   0.,   4.,
        400., 375.,   1.,   9.]), tensor([400., 125.,   1.,  10., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   2.,  13.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   2.,   4.]), tensor([400., 125.,   2.,   5., 200., 250.,   1.,   2., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   2.,   6., 600., 250.,   0.,   4.,
        400., 375.,   1.,   3.]), tensor([400., 125.,   2.,   2., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   2.,   0., 200., 250.,   1.,   2., 600., 250.,   0.,   4.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   1.,   7., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.]), tensor([400., 125.,   2.,  12., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   1.,   8.]), tensor([400., 125.,   1.,   9., 200., 250.,   2.,  13., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,   1., 600., 250.,   0.,   4.,
        400., 375.,   2.,   3.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   2.,   5.]), tensor([400., 125.,   2.,   6., 200., 250.,   1.,   0., 600., 250.,   0.,   4.,
        400., 375.,   1.,   2.]), tensor([400., 125.,   2.,   1., 200., 250.,   2.,   3., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   2.,   3., 200., 250.,   1.,   1., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 20152
Player 1 Actions: [(3, 0), (3, 1), (0, 2), (2, 2), (2, 3), (2, 2)]
Player 2 Actions: [(2, 2), (2, 3), (3, 0), (3, 3), (0, 3), (3, 2)]
Player 1 Rewards: [10, -8, 25, -10, 25, -10]
Player 2 Rewards: [0, 0, 0, 0, 0, -100]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   1.,   8., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   1.,  10., 200., 250.,   0.,   2., 600., 250.,   2.,   0.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   2.,   2., 200., 250.,   0.,   2., 600., 250.,   1.,  11.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   4., 200., 250.,   0.,   2., 600., 250.,   1.,   1.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   0.,   2., 600., 250.,   1.,   1.,
        400., 375.,   2.,   4.])]
Next States: [tensor([400., 125.,   1.,   7., 200., 250.,   0.,   4., 600., 250.,   2.,  11.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   9., 200., 250.,   0.,   2., 600., 250.,   2.,   1.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   2., 600., 250.,   1.,  10.,
        400., 375.,   2.,   2.]), tensor([400., 125.,   2.,   3., 200., 250.,   0.,   2., 600., 250.,   1.,   0.,
        400., 375.,   2.,   1.]), tensor([400., 125.,   2.,   5., 200., 250.,   0.,   2., 600., 250.,   1.,   0.,
        400., 375.,   1.,   1.]), tensor([400., 125.,   2.,   1., 200., 250.,   0.,   2., 600., 250.,   1.,   0.,
        400., 375.,   2.,   5.])]
==================================================
Epoch: 20610
Player 1 Actions: [(3, 0), (0, 1), (0, 3)]
Player 2 Actions: [(1, 3), (3, 3)]
Player 1 Rewards: [10, 10, 125]
Player 2 Rewards: [0, 0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   2.,  10., 600., 250.,   0.,   4.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   1.,   8., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.]), tensor([400., 125.,   1.,   1., 200., 250.,   1.,   9., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   1.,   7., 200., 250.,   2.,  11., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   1.,   8., 600., 250.,   0.,   4.,
        400., 375.,   2.,  12.])]
==================================================
Epoch: 21068
Player 1 Actions: [(0, 2), (0, 2), (0, 2), (0, 2), (0, 2)]
Player 2 Actions: [(2, 0), (2, 0), (2, 0), (2, 1)]
Player 1 Rewards: [-10, 15, 15, 15, 125]
Player 2 Rewards: [0, 0, 0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   3., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 21526
Player 1 Actions: [(0, 2), (0, 2), (0, 2)]
Player 2 Actions: [(2, 0), (2, 3)]
Player 1 Rewards: [-10, 15, 125]
Player 2 Rewards: [0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   3.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 21984
Player 1 Actions: [(3, 0), (3, 0)]
Player 2 Actions: [(0, 1)]
Player 1 Rewards: [-8, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   2.,   0., 200., 250.,   0.,   3., 600., 250.,   0.,   4.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 22442
Player 1 Actions: [(2, 2)]
Player 2 Actions: [(3, 2)]
Player 1 Rewards: [-10]
Player 2 Rewards: [-100]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   1.,  10.,
        400., 375.,   2.,  10.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   1.,   0.,
        400., 375.,   2.,  11.])]
==================================================
Epoch: 22900
Player 1 Actions: [(0, 0), (0, 3)]
Player 2 Actions: [(3, 3)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,  11.])]
==================================================
Epoch: 23358
Player 1 Actions: [(0, 1), (0, 1), (0, 1), (0, 1)]
Player 2 Actions: [(1, 0), (1, 0), (1, 3)]
Player 1 Rewards: [-8, 0, 0, 110]
Player 2 Rewards: [0, 0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   2.,  10., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   3.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   2.,   0., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 23816
Player 1 Actions: [(2, 1), (2, 1), (2, 2)]
Player 2 Actions: [(1, 2), (1, 1), (1, 2)]
Player 1 Rewards: [-10, 15, -10]
Player 2 Rewards: [0, 0, -100]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   2.,  10., 600., 250.,   1.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   0.,   4., 200., 250.,   2.,   0., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   0.,   4., 200., 250.,   2.,   0., 600., 250.,   1.,   1.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   2.,   0., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   0.,   4., 200., 250.,   2.,   0., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   0.,   4., 200., 250.,   2.,   1., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 24274
Player 1 Actions: [(3, 1), (3, 2)]
Player 2 Actions: [(2, 2)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   8., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,   7., 600., 250.,   2.,  11.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 24732
Player 1 Actions: [(2, 0), (2, 0)]
Player 2 Actions: [(0, 1)]
Player 1 Rewards: [-8, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   0.,   4., 600., 250.,   1.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   0.,   3., 600., 250.,   1.,   1.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 25190
Player 1 Actions: [(2, 0), (2, 0)]
Player 2 Actions: [(0, 0)]
Player 1 Rewards: [-8, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   0.,   4., 600., 250.,   1.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,   1.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 25648
Player 1 Actions: [(2, 0), (2, 0)]
Player 2 Actions: [(0, 1)]
Player 1 Rewards: [-8, 110]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   2.,  10., 200., 250.,   0.,   4., 600., 250.,   1.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   0.,   3., 600., 250.,   1.,   1.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   2.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 26106
Player 1 Actions: [(0, 2), (0, 2)]
Player 2 Actions: [(2, 3)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   3.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 26564
Player 1 Actions: [(0, 2), (0, 2)]
Player 2 Actions: [(2, 1)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   3., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 27022
Player 1 Actions: [(3, 1), (3, 2)]
Player 2 Actions: [(2, 2)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   0.,   4., 200., 250.,   1.,   8., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   1.,   7., 600., 250.,   2.,  11.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 27480
Player 1 Actions: [(0, 3), (0, 3), (0, 3), (0, 3), (0, 3), (0, 3)]
Player 2 Actions: [(3, 0), (3, 0), (3, 0), (3, 0), (3, 2)]
Player 1 Rewards: [-10, 15, 15, 15, 15, 125]
Player 2 Rewards: [0, 0, 0, 0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   0.,   3.,
        400., 375.,   2.,   0.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,   0.])]
==================================================
Epoch: 27938
Player 1 Actions: [(0, 2), (2, 1), (2, 0), (2, 1)]
Player 2 Actions: [(1, 0), (0, 1), (1, 1)]
Player 1 Rewards: [-3, 10, 10, 110]
Player 2 Rewards: [0, 0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   2.,  10., 600., 250.,   0.,   4.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,  11., 200., 250.,   2.,   0., 600., 250.,   1.,   8.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,   0., 200., 250.,   2.,   4., 600., 250.,   1.,   1.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   2., 200., 250.,   2.,   0., 600., 250.,   1.,   1.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   2.,  11., 600., 250.,   1.,   7.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   2.,  12., 200., 250.,   1.,   8., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   2.,   5., 600., 250.,   1.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 28396
Player 1 Actions: [(0, 2), (2, 3), (3, 0), (3, 1)]
Player 2 Actions: [(3, 0), (0, 1), (1, 1)]
Player 1 Rewards: [-10, 25, 10, 110]
Player 2 Rewards: [0, 0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   0.,   4.,
        400., 375.,   2.,  10.]), tensor([400., 125.,   2.,  11., 200., 250.,   0.,   4., 600., 250.,   1.,   8.,
        400., 375.,   2.,   0.]), tensor([400., 125.,   2.,   0., 200., 250.,   2.,   9., 600., 250.,   1.,   1.,
        400., 375.,   1.,   9.]), tensor([400., 125.,   1.,  10., 200., 250.,   2.,   0., 600., 250.,   1.,   3.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   1.,   7.,
        400., 375.,   2.,  11.]), tensor([400., 125.,   2.,  12., 200., 250.,   0.,   4., 600., 250.,   1.,   0.,
        400., 375.,   1.,   8.]), tensor([400., 125.,   1.,   9., 200., 250.,   2.,  10., 600., 250.,   1.,   2.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 28854
Player 1 Actions: [(0, 2), (0, 2)]
Player 2 Actions: [(2, 3)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   3.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
==================================================
Epoch: 29312
Player 1 Actions: [(3, 2), (3, 2)]
Player 2 Actions: [(2, 0)]
Player 1 Rewards: [-10, 125]
Player 2 Rewards: [0]
States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   1.,  10.]), tensor([400., 125.,   0.,   3., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,   1.])]
Next States: [tensor([400., 125.,   0.,   4., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   1.,   0.])]
==================================================
Epoch: 29770
Player 1 Actions: [(0, 2), (0, 2), (0, 2), (0, 2), (0, 2)]
Player 2 Actions: [(2, 0), (2, 0), (2, 0), (2, 2)]
Player 1 Rewards: [-10, 15, 15, 15, 125]
Player 2 Rewards: [0, 0, 0, 0]
States: [tensor([400., 125.,   1.,  10., 200., 250.,   0.,   4., 600., 250.,   2.,  10.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   1., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
Next States: [tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.]), tensor([400., 125.,   1.,   0., 200., 250.,   0.,   4., 600., 250.,   2.,   0.,
        400., 375.,   0.,   4.])]
==================================================
